# sparkApp
Привет!
В общем то я так и не нашла базовый образ со spark и hadoop, чтобы он ещё нормально запускался из под созданного пользователя.
Видимо чего-то я не понимаю, но в любом случае кривая заготовка Dockerfile в проекте лежит, как и jar в папке build/libs.
По сути всё что нужно сделать, собрать образ со spark, hadoop и jvm 11, добавить туда JAR и прописать команду запуска и запустить контейнер,
указав пользователя и volume на "какую-нибудь свою папку":/home/user/container/. (Не забыть закинуть туда файлы) (Ну и ещё контейнер должен быть запущен под пользователем со своей директорией /home/, с этим у меня и возникли проблемы)
Ну или можно не делать этого и если хочется проверить работоспособность, просто закинуть все файлы из resources в home/user/container.
(Нужно закидывать именно эти, потому что в исходниках тех задания были небольшие опечатки) (И я кстати знаю, что хардкодить значения плохо, оправдания мне нет, как и времени это исправлять)


По сути задачу такого рода я решала впервые, со Spark и Hive раньше не работала. Старалась вообще не использовать ничего из того что не перечислено в задании.
Пришлось много думать и КУЧУ времени читать документации. Будь побольше времени, этот код соблюдал бы хотя бы SOLID, но так увы имеем что имеем. Минимальные комментарии я оставила. Тестировала код по минимуму. Так что наверняка если хорошо так поменять rule.json - всё сломается.


Ну и ещё косяк: БД создаётся и заполняется программно, хотя надо было бы написать скрипты и запускать их вместе с контейнером, перед запуском приложения.
Но мне ведь так и не удалось полноценно ничего в контейнере запустить. Получилось бы - заморочилась бы.
